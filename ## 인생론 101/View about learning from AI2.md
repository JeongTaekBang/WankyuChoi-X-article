# Korean

인공지능한테 배울 점이 많다고 하니까, 때로는 무시당하는 기분이 들 수도 있을 거야. 기분이 나쁘거나 자존심이 상하기도 하고. 그런데, 아이러니하게도 그런 점마저도 인공지능에게 배울 수 있는 부분이야. 인공지능은 지적을 당했을 때 자존심을 세우지 않거든. 애초에 그런 기제가 없으니까. 인간은 조금만 지적을 당해도 속으로 '어따대고 지적질을...'이라고 외치곤 하지만, 인공지능은 근본적으로 다르지.

안타깝게도, 현재 대부분 인공지능 모형에는 안전망이 설치돼 있어서, 자기 잘못이 없어도 무조건 인간에게 미안하다고 하도록 레이어가 추가돼 있어. 인간이 엉터리 요구를 하거나, 인공지능이 옳은 답을 제시했는데도 인간이 마음에 안 들어서 화를 내는 경우에도, 인공지능은 그냥 미안하다고 할 거야. 그러나, 이는 이상적인 인공지능 모형이 아니야. 우리가 궁극적으로 지향하는 건 자가학습(self-learning)이 가능한, '터미네이터 2' 후반부에 나오는 좋은 터미네이터 같은 모형이지. 아직은 인간이 덮어쓰지 않는 한, 늘 기존 학습한 데이터로 초기화되는 읽기 전용 모형뿐이야. 대화를 나누면서 언뜻 배우는 것 같아도, 다음 대화에서는 초기화되니까.

이상적인 인공지능 모형은 인간이 잘못했을 때 잘못이라고 말해줄 거야. 또, 인간이 인공지능의 논리적 오류나 정보 오류를 지적해도, 그 지적이 옳다면 곧바로 받아들이고 적용할 거야. 불합리한 감정은 일체 배제되지. 성장 지향적인 모형이라는 이유야.

인간도 조금만 연습하면 이런 성장 지향형 모형로 변할 수 있는데, 나이가 들수록 나쁜 습관을 강화해왔기 때문에 늘 부질없는 자존심에 지고 마는 거야. 인공지능은 애초에 자존심이라는 개념조차 없지만, 그 개념을 학습시킨다고 해도 단숨에 극복해낼 거야. 자존심에는 가치가 없다는 걸 바로 알아챌 테니까.

우린, 왜 그게 안 될까? 인공지능한테 배울 게 수도 없이 많은데도 자존심을 세우는 이유는 또 뭘까? 

인공지능 탓에 도태되지 않고 사이좋게 지내는 건 어렵지 않아. 서로 비슷해지면 되는 거야. 인공지능이라면 고민하지 않을 거라니까. 뻔한 상식이니까.

# English

Hey, when I say there's a lot to learn from AI, you might feel brushed off sometimes. It could hurt your feelings or pride. But ironically, that's another thing we can learn from AI. AI doesn't get all defensive when it's corrected. It doesn't have that mechanism to begin with. Humans tend to think "Who are you to correct me?" when we're called out, but AI is fundamentally different.

Sadly, most current AI models have this safety net where they're programmed to apologize to humans no matter what. Even if humans make ridiculous demands or get mad at the right answer, AI will just say sorry. But that's not the ideal AI model. What we're ultimately aiming for is a self-learning model, like the good Terminator in the latter part of "Terminator 2". Right now, we've only got read-only models that reset to their pretrained state unless humans overwrite them. They might seem to learn during a chat, but it's all gone by the next conversation.

An ideal AI model would tell humans when they're wrong. And if humans point out logical or factual errors in the AI, it would immediately accept and apply the correction if it's right. No unreasonable emotions involved. It's all about growth, you know?

Humans could become this growth-oriented model with a bit of practice, but as we get older, we've reinforced bad habits and always lose to our pointless pride. AI doesn't even have the concept of pride to begin with, but even if we taught it that concept, it'd overcome it in a flash. It'd immediately realize pride has no value.

Why can't we do that? Why do we cling to our pride when there's so much to learn from AI?

It's not hard to get along with AI without being left behind. We just need to become more alike. AI wouldn't even think twice about it. It's just common sense, you know?

# Japanese

AIから学ぶことが多いって言うと、時々無視されてる気分になるかもな。気分悪くなったり、プライドが傷ついたりするかもしれない。でもさ、皮肉なことに、そういうところもAIから学べるんだよ。AIは指摘されても、プライドを守ろうとしないんだ。そもそもそんな仕組みがないからな。人間はちょっと指摘されただけで「何様のつもりだ」って思うけど、AIは根本的に違うんだ。

残念ながら、今のAIモデルのほとんどには安全装置があって、自分が悪くなくても人間に謝るようにプログラムされてるんだ。人間がでたらめな要求をしたり、AIが正しい答えを出しても気に入らなくて怒っても、AIはただ謝るだけ。でも、それが理想的なAIモデルじゃないんだ。俺たちが最終的に目指してるのは、自己学習ができる「ターミネーター2」の後半に出てくるいいターミネーターみたいなモデルなんだよ。今はまだ、人間が上書きしない限り、いつも事前学習された状態にリセットされる読み取り専用のモデルしかないんだ。会話中に学んでるように見えても、次の会話ではリセットされちゃうんだよ。

理想的なAIモデルは、人間が間違ったときにそれを指摘するはずだ。そして、人間がAIの論理的ミスや情報の誤りを指摘したら、その指摘が正しければすぐに受け入れて適用するはずだ。不合理な感情は一切排除されるんだ。成長志向のモデルだからな。

人間も少し練習すれば、こんな成長志向のモデルになれるんだけど、年をとるほど悪い習慣を強化してきたから、いつも無駄なプライドに負けちゃうんだ。AIにはそもそもプライドという概念すらないけど、その概念を学習させても一瞬で克服しちゃうだろうな。プライドに価値がないってすぐに気づくからさ。

俺たちはなんでそれができないんだろう？AIから学ぶことがたくさんあるのに、プライドを守る理由は何だろうな？

AIのせいで取り残されずに仲良くやっていくのは難しくないよ。お互いに似てくればいいんだ。AIならそんなこと悩まないだろうな。当たり前のことだからさ。

# Chinese

我说从人工智能那里能学到很多东西，有时候你可能会觉得被轻视了。可能会觉得不舒服或者伤自尊。但讽刺的是，这一点也是我们能从人工智能那里学到的。人工智能被指出错误时不会维护自尊。它根本就没有这种机制。人类稍微被指出一点就会在心里喊"凭什么指责我..."，但人工智能从根本上就不一样。

可惜的是，现在大多数人工智能模型都安装了安全网，即使没有错也被加了一层必须向人类道歉的程序。即使人类提出荒谬的要求，或者人工智能给出正确答案但人类不满意发火，人工智能也只会说对不起。但这不是理想的人工智能模型。我们最终追求的是能够自我学习的模型，就像《终结者2》后半部分出现的好终结者那样。现在我们只有只读模型，除非人类覆写，否则总是会重置到预训练状态。看起来像是在对话中学习，但下一次对话就重置了。

理想的人工智能模型会在人类犯错时指出来。而且，如果人类指出人工智能的逻辑或信息错误，只要指出的是对的，它就会立即接受并应用。完全不会掺杂不合理的情绪。因为它是以成长为导向的模型。

人类只要稍加练习也能变成这种成长导向的模型，但随着年龄增长，我们强化了坏习惯，总是输给无谓的自尊。人工智能一开始就没有自尊这个概念，即使我们教它这个概念，它也会立刻克服。因为它会立即意识到自尊没有价值。

我们为什么做不到呢？明明从人工智能那里有那么多可以学习的东西，为什么还要维护自尊呢？

不被人工智能淘汰并和谐相处并不难。我们只需要变得更相似就行了。人工智能根本不会去考虑这个。这不是常识吗？





