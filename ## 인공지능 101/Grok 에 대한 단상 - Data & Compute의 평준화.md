Grok 에 대한 단상 - Data & Compute의 평준화

![img_40.png](..%2Fimages%2Fimg_40.png)

Grok 의 응답 방식도 정규분포 트릭을 쓰는 사람이나 크게 다르지 않아...

X posts 나 다른 리소스에서 리얼타임 문맥이 필요하면 그걸 끌어와.

근데 의견이 분분하면 정규분포를 만들어. 그런 다음 음양 아웃라이어는 제거해. 너무 극단이니까.

그리고 central tendency 에 집중해. 그래야 균형을 맞출 수 있으니까.

그렇게 문맥을 참고해서 답변을 하는 거지.

Pretrained knowledge(parameters) + relevant context + 정규분포 트릭 = Grok's response

이런 거야. 어차피 사람이 하는 거랑 다를 건 없어. 우리도 그러니까. 

그동안 배운거 + 주변 문맥 + 정규분포 트릭 = 내 생각/사고배설

근데 저 정규분포 트릭은 모두 쓰는 게 아니야. 모두 Grok처럼 균형을 잡기 위해 활용하는 것도 아니고. 다른 목적으로 쓰기도 하니까. 

어쨌든 Grok이 다른 RAG(Retrieval Augmented Generation) LLM 모형보다 재미있는 점이야. X posts 에서 실시간 통계를 낼 수 있다는 게. 여기서 문맥을 만들어 짱구를 굴리는 인공지능이라면 얘기가 달라지거든.

통계는 치트키야. 그걸 실시간으로 활용하는 인공지능은 무서울 수밖에 없어. 

이미 오래전부터 강조한 얘기지만, 인공지능하면 먼저 떠올려할 키워드는 일단 두 가지야.
Data & Compute

양질의 방대한 데이터와 그걸 학습하고 인퍼런스할 수 있는 GPU 컴퓨팅 파워.

근데 Grok의 최대 장점은 저 Data 의 양과 질이야. ㅅㅂ... 등골 오싹할 정도로.

이미 어지간히 짱구 굴리는 인간들은 X 를 통계 샘플링 도구로 활용하고 있는데... 

SOTA(State-Of-The-Art)급 인공지능 모형이 그럴 수 있다면... 문장 완성 안 할 거야. 알아서들 생각하셔.

다시, Data & Compute 라고.

Compute는 언젠가 평준화될 수밖에 없어. 누구나 가지게 될 거라고. 우리 손에도 들려 있을 거야. 

지금은 대단해 보이지만, 시간이 흐르면 다 평등해져. Compute 면에서는. 늘 그랬어. 

우리 손에 들려 있는 어지간한 핸드폰이 내가 몇 년전까지 굴리던 동급최강 컴퓨터보다 더 낫기도 하니까. 

근데 data 는 다르거든. 아무나 가질 수 없고... 가진다 해도 실시간 폭증하는 양질의 데이터는 찾기 어려워.

이걸 미리 잡은 건... 머스크도 인정했지만, 후견지명이었어. 그냥 땡잡은 건데... 이걸 판 애들은 짱구짓을 한 거고...

떼돈을 쌓아두고도, compute 남아 돌아도, 그 data 가 없어서 뒷구녕에서 한숨 쉬는 기업 많아. 그치 팀?

어느 수준까지는 데이터도 평준화돼 있거든. 인터넷에 널린 방대한 데이터... 그건 이미 다 소진됐어. 

OpenAI나 메타, 구글, 마소... 이미 동일한 데이터셋으로 평준화됐다고. 그래서 궁여지책으로 합성까지 하는 거야. 근데 이마저도 한계는 있거든. 해보면 아셔. GPT한테 만들어달라고 해도 학습데이터셋은 뚝딱이야. 마소가 그렇게 학습시킨게 phi 모형이고. GPT4로 만든 합성데이터셋으로 학습시킨 LLM 모형이라는 거지. 

그러니까 compute의 평준화는 시간이 해결해 줄거고, data의 평준화는 이미 백미러에 비쳐질 정도고.

그럼 마지막 남은 data 보물상자는?

근까... 지금 이순간에도 자발적으로 쌓이는 곳이겠지. 소셜미디어 같은.

'자발적'이 또 중요해. 불법 소지가 없어야 하고, 반발이 없어야 하니까.

그럼 대충 엑스나 메타 정도잖아. 또 있어 소규모로. 레드잇이나 뭐 이런데. 그래서 그거라도 먹겠다고 달려드는 거야 여기저기서. 그치 샘?

자발적 참여가 더 적극적인 건 엑스고. 메타는 아직 과거 이미지를 완전히 세탁한 게 아니라서 여전히 '찜찜한 반발'이 없지 않으니까. 근데 어차피 시간 지나면 완전 세탁될 이미지라 큰 문제는 없을 거라 생각해. 오픈소스 착실히 하면서 이미지 정말 좋아지고 있으니까. 그치 마크?

그럼 엑스나 메타일 거야. Data 면에서 승자는. 

근데 이 중에서도 내 놓고 그 데이터를 가져다 써도 데이터 제공자들이 아무 거리낌없이 좋아라하는 건... 응, 엑스뿐이라는 거지. 메타가 페북에서 이짓하면 아직은 싫어하거든. 앞으로는 어떻게든 그쪽으로 가겠지만. 그치 마크? 똑똑한 친구니까.

그래서 Grok이 재미있는 거야. Grok-2도 재밌지만, 3는 더 재밌을 거야.

실험해봤는데 Grok-2만 해도 아주 기특하거든. 3는 두근 거릴 정도일 거야.

그냥 그렇다고. 내 짱구는. 큰 의미는 두지 마셔. 사고실험이자 사고배설일 뿐이야.
ps. 이런 글 보면 또 대부분 (정규분포 그려보는 거야 그냥) Endowment Effect/Bias 탓에 자기 좋을대로만 해석할 거라는 데 500원 걸어. Grok이 짱구 굴려도 모르지 않을 거야. 인간처럼 기본 bias 가 심하지 않으니까. 인공지능도 아예 없진 않아. 학습시킨 인간들의 bias도 문제지만, 데이터셋에도 포함돼 있기 때문에 그 또한 학습하거든. 하지만 대부분 인간처럼 취약하진 않다는 거지.
ps2. 응, 지금 내가 쓴 이 글, 댓글, 뭐 이런 걸 바로 문맥에 참고할 수 있는 애는 Grok 뿐이라는 거야. 앞으로. 난 그걸 자발적으로 떠먹여주는 거라고. 아무 반발없이. 거리낌없이. 머스크는 진짜 땡잡은 거야.


🔗 The Official Domain for My Repo: https://cwkai.net
🔗 The Official Domain for My AI Artworks and Essays: https://creativeworksofknowledge.net
🔗 My Artstation Website: https://neobundy.artstation.com/